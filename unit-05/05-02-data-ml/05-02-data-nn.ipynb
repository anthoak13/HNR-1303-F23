{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJ7uToePod9CrYcCU8dilO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Breaking a simple neural network\n",
        "\n",
        "In this notebook we will take the neural net we constructed last class and try to break it. How? By messing with the data we use to train it.\n",
        "\n",
        "My goal for this notebook is for you to understand the importance of data in training a neural network. If our data is incomplete or incorrect in some manner, then our model will be garbage (even if our cost function might look alright)\n",
        "\n",
        "**Before running any code**: Go to `Runtime->Change runtime type` and select `T4 GPU`.\n",
        "\n",
        "Run the cell below to import all of the python packages we will require in this notebook. You should see the device is CUDA and the GPU is availible."
      ],
      "metadata": {
        "id": "YR4G-yQdiQw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path # internal python library for managing file paths\n",
        "import requests # used to doqload files using web requests\n",
        "import pickle\n",
        "import gzip # used to unzip files\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import curve_fit\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "import copy\n",
        "from google.colab import files\n",
        "import random\n",
        "\n",
        "gpu_avail = torch.cuda.is_available()\n",
        "print(f\"Is the GPU available? {gpu_avail}\")\n",
        "device = torch.device(\"cuda\") if gpu_avail else torch.device(\"cpu\")\n",
        "print(\"Device\", device)"
      ],
      "metadata": {
        "id": "EM7Iw80_jAtd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f184bb2e-d062-41e6-b4b2-a5a3af850740"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is the GPU available? True\n",
            "Device cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting the MINST dataset\n",
        "\n",
        "Run the cell below to download and unpack the MINST dataset (this is the same as last notebook)."
      ],
      "metadata": {
        "id": "6ZJ-yH3ri0ra"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4_5YgKEjiP19"
      },
      "outputs": [],
      "source": [
        "data_path = Path(\"data\")\n",
        "path = data_path/\"mnist\" # this defines the file path as data/mnist\n",
        "path.mkdir(parents=True, exist_ok=True) # this creates the folders \"data\" and \"data/mnist\"\n",
        "\n",
        "data_url = \"https://github.com/pytorch/tutorials/raw/main/_static/\"\n",
        "data_filename = \"mnist.pkl.gz\"\n",
        "\n",
        "if not (data_path / data_filename).exists():\n",
        "  content = requests.get(data_url + data_filename).content\n",
        "  (data_path/data_filename).open(\"wb\").write(content)\n",
        "\n",
        "with gzip.open((data_path / data_filename).as_posix(), \"rb\") as unpacked_data:\n",
        "  ((image_train, label_train), (image_valid, label_valid), _) = pickle.load(unpacked_data, encoding=\"latin-1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# (Re-)Building a neural network\n"
      ],
      "metadata": {
        "id": "rxokNQ9uoVdT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the code cells in this section to re-build the differnt parts of the neural network. These cells will define the cost function, the activation function, and the structure of the neural net (number of hidden layers, etc.)"
      ],
      "metadata": {
        "id": "mKppk9wEpTmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the cost function that takes in the model prediction (input) and the expected output by the model (target)\n",
        "def cost_func(input, target):\n",
        "   cost = torch.nn.MSELoss(reduction='sum')\n",
        "   return cost(input, target)\n",
        "\n",
        "# Define a function that takes in a digit (0-9) and creates the corresponding model target\n",
        "def get_target(digits):\n",
        "  target = F.one_hot(torch.tensor(digits, device = device), 10)\n",
        "  return target\n",
        "\n",
        "# Define the activation function\n",
        "activation_func = F.sigmoid\n",
        "\n",
        "# Define the structure of the neural net\n",
        "class NN_Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.hidden1 = nn.Linear(784,16) # Our input layer has 784 neurons and our first hidden layer has 16 elements\n",
        "    self.hidden2 = nn.Linear(16,16) # Our second hidden layer has 16 inputs and 16 outputs\n",
        "    self.output = nn.Linear(16,10) # Our output layer has 16 inputs and 10 outputs\n",
        "\n",
        "  def forward(self, xb):\n",
        "    # xb is the value of all the neurons at the current layer.\n",
        "    # At the start it is a tensor with 784 elements\n",
        "\n",
        "    # Do the matrix multiplication and then take the sigmoid of each element in the first hidden layer.\n",
        "    xb = activation_func(self.hidden1(xb))\n",
        "    # xb is now a tensor with 16 elements\n",
        "\n",
        "    # Do the matrix multiplication and then take the sigmoid of each element in the second hidden layer.\n",
        "    xb = activation_func(self.hidden2(xb))\n",
        "    # xb is now a tensor with 16 elements\n",
        "\n",
        "    # Do the matrix multiplication and then take the sigmoid of each element in the output layer.\n",
        "    xb = activation_func(self.output(xb))\n",
        "    # xb is now a tensor with 10 elements\n",
        "\n",
        "    return xb"
      ],
      "metadata": {
        "id": "5KjoNfurtI3H"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Training the model"
      ],
      "metadata": {
        "id": "iD-zdFK1ENFi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the cell below to define the training function. This is a slightly more sophisticated version of the training function we have used in the past. It takes in both the training data and the validation data. It also uses the abstract `Dataset` class and the helper class `DataLoader` from PyTorch to simplify the managment of the data and creating batches to train on.\n",
        "\n",
        "**For those intrested in the details**: This information is not necessary for understanding anything in our class, but is here for those who are intrested in digging into the details of how python handles data structures. The `Dataset` class wraps any object that implements the [`__len__()`](https://docs.python.org/3/reference/datamodel.html#object.__len__) and [`__getitem__()`](https://docs.python.org/3/reference/datamodel.html#object.__getitem__) functions in Python. These are both examples of so-called [\"magic functions\"](https://rszalski.github.io/magicmethods/) in Python. They are what underly a lot of the power of Python which I would argue is the ability to basically ignore the specific type an object is. Instead we treat object logically. Is it an array like object, then `a[0]` should do something. Personally, I've never really liked the name \"magic functions\". What they really are is an [Interface](https://en.wikipedia.org/wiki/Interface_(object-oriented_programming) which defines a set of *behaviors*. Any class can then agree to follow and implement the interface. All of these classes can be used interchangibly (in certain contexts). The two functions we need implemented are part of [the group of magic functions](https://docs.python.org/3/reference/datamodel.html#emulating-container-types) that allow for us to iterate through a container. `__len__(self)` is what is called whenever you run `len(obj)`. `__getitem__(self, key)` is called whenever you run something like `self[key]`. Both are fundemental to the design of a data structure and are part of the interface that allows you to mostly treat all data structures the same way in Python. Isn't object oriented programming fun?"
      ],
      "metadata": {
        "id": "sKbSxZybGUdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will define a function for training out model:\n",
        "# epochs is the number of times we pass over the complete training set.\n",
        "# batch_size is how many training examples to combine before updating the model parameters\n",
        "# learning_rate controls how large of a step we take each time we update the model parameters\n",
        "# data_train is the list of images we are training on (the entirety of this dataset corresponds to a single epoch)\n",
        "# label_train is the list of labels corresponding to the images in data_train\n",
        "# model is the model we are training\n",
        "\n",
        "# The function will return a list containing the average cost function after each epoch\n",
        "def train_model(epochs, batch_size, learning_rate, data_train, label_train, model, data_valid = None, label_valid = None):\n",
        "\n",
        "  # Create lists to return\n",
        "  cost_valid = []\n",
        "  cost_train = []\n",
        "  models = []\n",
        "\n",
        "  # Create the optimizer to perform the gradient descent\n",
        "  opt = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  # Wrap the training data in a dataset\n",
        "  train_ds = torch.utils.data.TensorDataset(torch.tensor(data_train, device = device), get_target(label_train))\n",
        "  train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size)\n",
        "\n",
        "  # We will repeat the training process multiple times, printing the current average of the cost function after each epoch\n",
        "  for epoch in range (epochs):\n",
        "\n",
        "    # Each iteration of this loop will evaluate the model\n",
        "    # on a subset of the data containing batch_size images\n",
        "    for xb, yb in train_dl:\n",
        "      pred = model(xb)\n",
        "      cost = cost_func(pred, yb.float())\n",
        "\n",
        "      # Update the model parameters (i.e. train the model)\n",
        "      # for this batch of data\n",
        "      cost.backward()\n",
        "      opt.step()\n",
        "      opt.zero_grad()\n",
        "\n",
        "    # End of batch_size loop\n",
        "\n",
        "    xb = torch.tensor(data_train, device=device)\n",
        "    yb = get_target(label_train)\n",
        "    pred = model(xb)\n",
        "\n",
        "    # calculate the average cost function\n",
        "    cost = cost_func(pred, yb) / len(pred)\n",
        "\n",
        "    xb = torch.tensor(data_valid, device=device)\n",
        "    yb = get_target(label_valid)\n",
        "    pred = model(xb)\n",
        "\n",
        "    # calculate the average cost function\n",
        "    cost_v = cost_func(pred, yb) / len(pred)\n",
        "\n",
        "    print(f\"After epoch {epoch} the cost function is {cost}\")\n",
        "    cost_valid.append(cost_v.item())\n",
        "    cost_train.append(cost.item())\n",
        "    models.append(copy.deepcopy(model))\n",
        "\n",
        "  return cost_valid, cost_train, models\n",
        "\n",
        "# Return the predicted digit from the output of the model\n",
        "def get_digit(pred):\n",
        "  return torch.argmax(pred, dim=0)\n",
        "\n",
        "def accuracy(pred, xy):\n",
        "  num_right = 0\n",
        "  for i in range(pred.shape[0]):\n",
        "    if get_digit(pred[i]) == get_digit(xy[i]):\n",
        "      num_right += 1\n",
        "\n",
        "  return num_right / pred.shape[0]"
      ],
      "metadata": {
        "id": "60mdl40q7drw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get a working model\n",
        "\n",
        "Run the following code to train the model using some default hyperparameters:"
      ],
      "metadata": {
        "id": "b7y77TpYjBGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters for training\n",
        "learning_rate = 0.05\n",
        "batch_size = 100\n",
        "num_epochs = 100\n",
        "\n",
        "# This will default to creating a model with random weights and biases.\n",
        "torch.manual_seed(0) # This will fix it so we all get the same data\n",
        "if torch.cuda.is_available():\n",
        "  torch.cuda.manual_seed(0)\n",
        "  torch.cuda.manual_seed_all(0)\n",
        "\n",
        "model = NN_Model()\n",
        "model.to(device)\n",
        "\n",
        "# Train the data. Save the average cost function and the model after each epoch\n",
        "costs_valid, costs, models = train_model(num_epochs, batch_size, learning_rate, image_train, label_train, model, data_valid = image_valid, label_valid=label_valid)\n",
        "\n",
        "#torch.save(model, 'testModel.pth')\n",
        "#files.download('testModel.pth')\n",
        "epochs = [i for i in range(len(costs))]\n",
        "\n",
        "# plot the cost function as a function of epoch\n",
        "fig = plt.figure(figsize=(8,6))\n",
        "plt.title(\"Cost function vs. training epoch\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Cost function (arb)')\n",
        "plt.grid(which='both', axis='both')\n",
        "plt.plot(epochs, costs, 'r-', label=\"Training set\")\n",
        "plt.plot(epochs, costs_valid, 'b-', label=\"Validation set\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Lk74yF6xNwE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# When is a model done learning?\n",
        "\n",
        "**Based on the cost curves you generated above, how does the long-term behavior of the cost function differ between the validation set and the training set?**\n",
        "\n",
        "**Around what epoch does the validation curve level off?**\n",
        "\n",
        "**What do you think is happening here?**\n",
        "\n",
        "\n",
        "Run the code below to fit the long term behavior of the cost function for our two data sets.\n"
      ],
      "metadata": {
        "id": "d2UHD7zG-NzG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model = lambda x,a,b: x*a + b\n",
        "\n",
        "trunc_epoch = epochs[20:]\n",
        "trunc_train = costs[20:]\n",
        "trunc_valid = costs_valid[20:]\n",
        "\n",
        "params, cov = curve_fit(linear_model, trunc_epoch, trunc_train)\n",
        "model_train = linear_model(np.array(trunc_epoch), *params)\n",
        "print(f\"The slope of the cost curve for the training data is {params[0]:.2e}.\")\n",
        "\n",
        "params, cov = curve_fit(linear_model, trunc_epoch, trunc_valid)\n",
        "model_valid = linear_model(np.array(trunc_epoch), *params)\n",
        "print(f\"The slope of the cost curve for the validation data is {params[0]:.2e}.\")\n",
        "\n",
        "# plot the cost function as a function of epoch\n",
        "fig = plt.figure(figsize=(8,6))\n",
        "plt.title(\"Cost function vs. training epoch\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Cost function (arb)')\n",
        "plt.grid(which='both', axis='both')\n",
        "plt.plot(trunc_epoch, costs[20:], 'r-', label=\"Training set\")\n",
        "plt.plot(trunc_epoch, model_train, 'r--', label=\"Linear fit\")\n",
        "plt.plot(epochs[20:], costs_valid[20:], 'b-', label=\"Validation set\")\n",
        "plt.plot(trunc_epoch, model_valid, 'b--', label=\"Linear fit\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6mwgHpfmAWyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What does it mean for the validity of our model that the slope for the training set is negative and the slope for the validation set is positive?**"
      ],
      "metadata": {
        "id": "QNrrxj8PCuJH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training with bad data\n",
        "\n",
        "Machine learning models are only as good as the data they are given. Suppose we where to shuffle of the labels in our training set. That is, each image in our training set is assigned to a random number as a label.\n",
        "\n",
        "**What do you think the cost curves will look like for the training and validation sets?**\n",
        "\n",
        "\n",
        "After writing your prediction, run the following code to find out."
      ],
      "metadata": {
        "id": "IqXZR1JYDFL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters for training\n",
        "learning_rate = 0.05\n",
        "batch_size = 100\n",
        "num_epochs = 100\n",
        "\n",
        "# This will default to creating a model with random weights and biases.\n",
        "torch.manual_seed(0) # This will fix it so we all get the same starting model\n",
        "model = NN_Model()\n",
        "model.to(device)\n",
        "\n",
        "label_sh = copy.deepcopy(label_train) # Make a copy of our labels\n",
        "random.shuffle(label_sh) # Shuffle our labels at random\n",
        "\n",
        "# Train the data. Save the average cost function and the model after each epoch\n",
        "costs_valid_sh, costs_sh, models_sh = train_model(num_epochs, batch_size, learning_rate, image_train, label_sh, model, data_valid = image_valid, label_valid=label_valid)\n",
        "epochs_sh = [i for i in range(len(costs_sh))]\n"
      ],
      "metadata": {
        "id": "EU-6WJ3fDB_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# plot the cost function as a function of epoch\n",
        "fig = plt.figure(figsize=(8,6))\n",
        "plt.title(\"Cost function vs. training epoch\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Cost function (arb)')\n",
        "plt.grid(which='both', axis='both')\n",
        "plt.plot(epochs_sh, costs_sh, 'r-', label=\"Training set\")\n",
        "plt.plot(epochs_sh, costs_valid_sh, 'b-', label=\"Validation set\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Fa_p1_5CGAF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is the long term behavior for both cost curves?**\n",
        "\n",
        "**How do the cost curves differ from when we are training with good data?**\n",
        "\n",
        "\n",
        "Let's look for a second at the accuracy as a function of epoch. It's a little easier to interpate. **If our model was just guessing, what would the expected accuracy of the model be?**\n",
        "\n",
        "After making your prediction, run the two code cells below to calcualte and plot accuracy vs epoch (it'll take a bit, there is a lot of data to churn through, if you want to edit the plot just run the second cell)."
      ],
      "metadata": {
        "id": "cE7Z4CPHGUv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = get_target(label_sh)\n",
        "target_valid = get_target(label_valid)\n",
        "acc_train = []\n",
        "acc_valid = []\n",
        "for model, epoch in zip(models_sh, range(len(models_sh))):\n",
        "  if epoch % 10 == 0:\n",
        "    print(\"On epoch \", epoch, \" of \", len(models_sh))\n",
        "\n",
        "  pred = model(torch.tensor(image_train, device=device))\n",
        "  acc_train.append(accuracy(pred, target))\n",
        "\n",
        "\n",
        "  pred = model(torch.tensor(image_valid, device=device))\n",
        "  acc_valid.append(accuracy(pred, target_valid))\n"
      ],
      "metadata": {
        "id": "NdGdzNZBHSrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_model = lambda x, a, b, c, d: a/(1+np.exp(-b*(x-c))) + d\n",
        "\n",
        "trunc_epoch = epochs_sh[0:]\n",
        "trunc_train = costs_sh[0:]\n",
        "trunc_valid = costs_valid_sh[0:]\n",
        "\n",
        "params, cov = curve_fit(log_model, trunc_epoch, acc_train, p0=[.03, 1, 45, .12])\n",
        "model_train = log_model(np.array(trunc_epoch), *params)\n",
        "print(f\"The carrying capacity of the cost curve for the training data is {(params[0]+params[3])*100:.2f}%.\")\n",
        "\n",
        "\n",
        "# plot the cost function as a function of epoch\n",
        "fig = plt.figure(figsize=(8,6))\n",
        "plt.title(\"Accuracy vs. training epoch\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(which='both', axis='both')\n",
        "plt.plot(epochs_sh, acc_train, 'r-', label=\"Training set\")\n",
        "plt.plot(epochs_sh, acc_valid, 'b-', label=\"Validation set\")\n",
        "plt.plot(epochs_sh, model_train, 'r--', label=\"Logistic fit\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3DxS8R3DItJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What do you notice about the accuracy? Is one dataset better than random? Is one dataset worse than random?**\n",
        "\n",
        "**Why do you think the accuracy for the trainins set is leveling off? It is fit quite well by a logisitic function.**\n",
        "\n",
        "**What do you think would happen if we were to only train on $100$ examples instead of $50,000$ (with the wrong labels)?**"
      ],
      "metadata": {
        "id": "WEQ7oAt2If7_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The code below will train a series of models on only 100 events with the labels shuffled."
      ],
      "metadata": {
        "id": "_uYEszBvOpaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters for training\n",
        "learning_rate = 0.05\n",
        "batch_size = 100\n",
        "num_epochs = 1000\n",
        "\n",
        "# This will default to creating a model with random weights and biases.\n",
        "torch.manual_seed(0) # This will fix it so we all get the same data\n",
        "model = NN_Model()\n",
        "model.to(device)\n",
        "\n",
        "label_100 = label_sh[:100]\n",
        "data_100 = image_train[:100]\n",
        "\n",
        "# Train the data. Save the average cost function and the model after each epoch\n",
        "costs_valid_100, costs_100, models_100 = train_model(num_epochs, batch_size, learning_rate, data_100, label_100, model, data_valid = image_valid, label_valid=label_valid)\n",
        "epochs_100 = [i for i in range(len(costs_100))]\n",
        "\n",
        "# plot the cost function as a function of epoch\n",
        "fig = plt.figure(figsize=(8,6))\n",
        "plt.title(\"Cost function vs. training epoch\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Cost function (arb)')\n",
        "plt.grid(which='both', axis='both')\n",
        "plt.plot(epochs_100, costs_100, 'r-', label=\"Training set\")\n",
        "plt.plot(epochs_100, costs_valid_100, 'b-', label=\"Validation set\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "y8Q6H_tyOnRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at the accuracy as well. Once again this will take while to run. While it's running, make a prediction for what you think the accuracy of the training data will be.\n",
        "\n",
        "**What is the highest accuracy you think we can achieve for the training data?**\n",
        "\n",
        "**At that same time, what do you think the accuracy of the validation set will be?**"
      ],
      "metadata": {
        "id": "jWBn5BtkPhab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = get_target(label_100)\n",
        "target_valid = get_target(label_valid)\n",
        "acc_train_100 = []\n",
        "acc_valid_100 = []\n",
        "for model, epoch in zip(models_100, range(len(models_100))):\n",
        "  if epoch % 10 == 0:\n",
        "    print(\"On epoch \", epoch, \" of \", len(models_100))\n",
        "\n",
        "  pred = model(torch.tensor(image_train[:100], device=device))\n",
        "  acc_train_100.append(accuracy(pred, target))\n",
        "\n",
        "\n",
        "  pred = model(torch.tensor(image_valid, device=device))\n",
        "  acc_valid_100.append(accuracy(pred, target_valid))\n",
        "print(\"Done calculating accuracy. Run next cell for plot\")"
      ],
      "metadata": {
        "id": "-2evPKtWPg69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_model = lambda x, a, b, c, d: a/(1+np.exp(-b*(x-c))) + d\n",
        "\n",
        "trunc_epoch = epochs_100[0:]\n",
        "trunc_train = costs_100[0:]\n",
        "trunc_valid = costs_valid_100[0:]\n",
        "\n",
        "params, cov = curve_fit(log_model, trunc_epoch, acc_train_100, p0=[.9, 1, 40, .12])\n",
        "model_train = log_model(np.array(trunc_epoch), *params)\n",
        "print(f\"The carrying capacity of the cost curve for the training data is {(params[0]+params[3])*100:.2f}%.\")\n",
        "\n",
        "# plot the cost function as a function of epoch\n",
        "fig = plt.figure(figsize=(8,6))\n",
        "plt.title(\"Accuracy vs. training epoch\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(which='both', axis='both')\n",
        "#plt.plot(epochs_100, acc_train_100, 'r-', label=\"Training set\")\n",
        "plt.plot(epochs_100, acc_valid_100, 'b-', label=\"Validation set\")\n",
        "#plt.plot(epochs_100, model_train, 'r--', label=\"Logistic fit\")\n",
        "#plt.plot(epochs_100, model_valid, 'b--', label=\"Validation set\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "fig = plt.figure(figsize=(8,6))\n",
        "plt.title(\"Accuracy vs. training epoch\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(which='both', axis='both')\n",
        "plt.plot(epochs_100, acc_train_100, 'r-', label=\"Training set\")\n",
        "#plt.plot(epochs_100, acc_valid_100, 'b-', label=\"Validation set\")\n",
        "plt.plot(epochs_100, model_train, 'r--', label=\"Logistic fit\")\n",
        "#plt.plot(epochs_100, model_valid, 'b--', label=\"Validation set\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1zE8muwxP8cV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compare your prediction to what you saw in the above plot.**\n",
        "\n",
        "**How does the maximum accuracy of the training set with 100 example? With 50,000 examples?**\n",
        "\n",
        "**Why can our model memorize the smaller training set, but not the larger training set? How could we modify our model so it could learn the full training set?**\n",
        "\n",
        "**Why do you think the accuracy on the validation set is improving beween epoch 600 and 1000? What accuracy is it trending towards?**"
      ],
      "metadata": {
        "id": "9AYodcLyQ1YK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bad data, bad model\n",
        "\n",
        "We just trained a model that achieved 99% accuracy! That right there with the worlds best models, right? There's just one problem. It performs worse then guessing on any image it hasn't seen before. Not the most useful model, is it? This is an exmaple of **over-training** or **over-fitting**. We hyper-specalize our model to the point of uselessness. We say this even before we taught our model to memorize 100 images. In our model at the start of this notebook the cost function of the validation set began creeping up over time even as the cost function of the training set continued to fall. That's a clear sign that we began to over-fit our model.\n",
        "\n",
        "# Universality of Neural Networks\n",
        "In any machine learning model, the data used to train it is the *most* important component. [The Universal Approximation Theorem](https://towardsdatascience.com/neural-networks-and-the-universal-approximation-theorem-8a389a33d30a) guarantees that a neural network (with enough complexity) can be used to approximate *any* function, regardless of the number of inputs or outputs. Assuming of course, we have enough examples of the function to show the neural net.\n",
        "\n",
        "The fact that you need data to train any useful model is, I would argue, one of the [dominent forces in the economy](https://www.economist.com/special-report/2020-02-22) (particularly in the tech sector). Any company that provides a free service on the internet (social media, Google, etc.) is probably in the buisness of collecting and using user data. This is often the driving force (or at least *a* driving force) behind decisions around availability of data through APIs. In the past year, [Twitter](https://www.theverge.com/2023/2/2/23582615/twitter-removing-free-api-developer-apps-price-announcement) and [Reddit](https://en.wikipedia.org/wiki/2023_Reddit_API_controversy) both made large changes to their API pricing structures. Reddit's CEO has [talked explicity](https://www.nytimes.com/2023/04/18/technology/reddit-ai-openai-google.html) about how the change is motivated by a desire to profit off of the data (post and comments on reddit) that is being used to train large language models like the one that underlies ChatGPT."
      ],
      "metadata": {
        "id": "86tcGfnXG2vX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework\n",
        "\n",
        "Pick some situation where you encounter (or thing you encounter) some machine learning based model or algorithm. Suppose you were to design that algorithm:\n",
        "\n",
        "1. What is the algorithm doing?\n",
        "1. What is the cost function for the algorithm?\n",
        "1. What data would you need to train this model? What are the inputs and outputs of the model?"
      ],
      "metadata": {
        "id": "98wC4aHRareo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WE2cgvXKaSKg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}